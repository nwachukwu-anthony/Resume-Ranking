{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textract\n",
    "# !pip install tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import textract\n",
    "from tika import parser\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./../Data/Resumes/\"\n",
    "save_to_path = \"./../Data/Workin_Data/\"\n",
    "\n",
    "for filename in glob.glob(path+\"~*\"):\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import shutil\n",
    "\n",
    "\n",
    "class Utils:\n",
    "    \"\"\"\n",
    "    Class containing methods that serve as helper functions\n",
    "    \"\"\"\n",
    "    \n",
    "    def shuffle_data(self, data_pd):\n",
    "        \"\"\"\n",
    "        Data shuffling\n",
    "        \"\"\"\n",
    "        \n",
    "        data_columns = data_pd.columns\n",
    "        data_body = data_pd[data_columns]\n",
    "        data_body = shuffle(data_body)\n",
    "\n",
    "        return data_body\n",
    "    \n",
    "    def string_to_words(self, query):\n",
    "        \"\"\"\n",
    "        from string of words to list of processed words\n",
    "        \"\"\"\n",
    "        \n",
    "        nltk.download(\"stopwords\", quiet=True)\n",
    "        try:\n",
    "            # add_similar_words_to_search_query(query[-1])\n",
    "            text = BeautifulSoup(query[-1], \"html.parser\").get_text()  # Remove HTML tags\n",
    "            text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())  # Remove non-alphanumeric and Convert to lower case\n",
    "        except:\n",
    "            text = ''\n",
    "        word_list = text.split()  # Split string into words\n",
    "        word_list = [w for w in word_list if w not in stopwords.words(\"english\")]  # Remove stopwords\n",
    "        word_list = [PorterStemmer().stem(w) for w in word_list]  # stem\n",
    "\n",
    "        return [query[0], word_list]\n",
    "    \n",
    "    def clean_data(self, data, cache_dir, cache_file=\"cleaned_data.pkl\"):\n",
    "        \"\"\"\n",
    "        Convert each data row to words; read from cache if available.\n",
    "        input: dataframe with columns key->col1, value->col2\n",
    "        output: list of lists, e.g [[employee1_id,body1_word_list],[employee2_id,body2_word_list],...]\n",
    "        \"\"\"\n",
    "\n",
    "        data_keys, data_body = data[data.columns[0]].values, data[data.columns[1]].values\n",
    "        data_train = [[data_keys[i], data_body[i]] for i in range(len(data_body))]\n",
    "\n",
    "        # If cache_file is not None, try to read from it first\n",
    "        cache_data = None\n",
    "        if cache_file is not None:\n",
    "            try:\n",
    "                with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
    "                    cache_data = pickle.load(f)\n",
    "                print(\"Read cleaned data from cache file:\", cache_file)\n",
    "            except:\n",
    "                pass  # unable to read from cache, but that's okay\n",
    "\n",
    "        # If cache is missing, then do the heavy lifting\n",
    "        if cache_data is None:\n",
    "            # Preprocess the data to obtain words for each employee data\n",
    "            words_train = list(map(self.string_to_words, data_train))\n",
    "\n",
    "            # Write to cache file for future runs\n",
    "            if cache_file is not None:\n",
    "                cache_data = dict(words_train=words_train)\n",
    "                with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
    "                    pickle.dump(cache_data, f)\n",
    "                print(\"Wrote preprocessed data to cache file:\", cache_file)\n",
    "        else:\n",
    "            # Unpack data loaded from cache file\n",
    "            words_train = (cache_data['words_train'])\n",
    "\n",
    "        return words_train\n",
    "    \n",
    "    def add_data_to_pickle(self, data_file, data=None, path='./'):\n",
    "\n",
    "        data_path = path + data_file\n",
    "\n",
    "        data_file_name = data_file.split('.')[0]\n",
    "        pickle_file_name = path + 'data_dict.pkl'\n",
    "\n",
    "        if os.path.isfile(pickle_file_name):\n",
    "            pickle_file = open(pickle_file_name, 'rb')\n",
    "        else:\n",
    "            pickle_file = open(pickle_file_name, 'bw')\n",
    "            pickle_file.close()\n",
    "\n",
    "        if os.path.getsize(pickle_file_name) > 0:\n",
    "            data_collections = pickle.load(pickle_file)\n",
    "            pickle_file.close()\n",
    "        else:\n",
    "            data_collections = {}\n",
    "\n",
    "\n",
    "        data_collections[data_file_name] = data\n",
    "        with open(pickle_file_name, 'bw') as f:\n",
    "            pickle.dump(data_collections, f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecruitmentPreprocess:\n",
    "    \"\"\"\n",
    "    Class for preprocessing job offer and resume text queries.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, resume_path, save_to_path):\n",
    "        self.resume_path = resume_path\n",
    "        self.save_to_path = save_to_path\n",
    "        self.resume_id_index, self.resume_id_data, self.resume_data = self.__merge_resume_to_dataframe()\n",
    "\n",
    "    def __extract_text_from_resume(self, file_name):\n",
    "        if file_name.split('.')[-1] == \"pdf\":\n",
    "            text = parser.from_file(self.resume_path + file_name)['content']\n",
    "        else:\n",
    "            text = textract.process(self.resume_path + file_name).decode()\n",
    "        return text\n",
    "\n",
    "\n",
    "    def __merge_resume_to_dataframe(self):\n",
    "\n",
    "        all_collection = []\n",
    "        all_files = [file.split('\\\\')[-1] for file in glob.glob(path + \"*\") if not file.startswith('~')]\n",
    "        index = 1\n",
    "        resume_id_index = {}\n",
    "        resume_id_data = {}\n",
    "        \n",
    "        for file in all_files:\n",
    "            if file.split('.')[-1] in ['docx', 'pdf', 'doc']:\n",
    "                resume_id_index[index] = '{}_{}'.format(file.split('.')[:-1],index)\n",
    "                resume_id_data[index] = self.__extract_text_from_resume(file)\n",
    "                collection = [index, self.__extract_text_from_resume(file)]\n",
    "                all_collection.append(collection)\n",
    "                index += 1\n",
    "\n",
    "        return resume_id_index, resume_id_data, pd.DataFrame(all_collection, columns=['employee_id', 'data'])\n",
    "\n",
    "    \n",
    "    def save_resume_data_to_csv(self):\n",
    "        \n",
    "        self.resume_data.to_csv(self.save_to_path + 'resume_data.csv', index=False)\n",
    "        \n",
    "    def add_resume_keys_to_pickle(self):\n",
    "        \n",
    "        utils = Utils()\n",
    "        utils.add_data_to_pickle('resume_id_index', self.resume_id_index, self.save_to_path)\n",
    "        \n",
    "    def add_user_accessible_resume_to_pickle(self):\n",
    "        \n",
    "        utils = Utils()\n",
    "        utils.add_data_to_pickle('user_accessible_resume', self.resume_id_data, self.save_to_path)\n",
    "        \n",
    "    def add_processed_resume_to_pickle(self):\n",
    "        \n",
    "        cache_directory = os.path.join(\"cache\", \"words_tokens\")  # where to store cache files\n",
    "        os.makedirs(cache_directory, exist_ok=True)  # ensure cache directory exists\n",
    "\n",
    "        cache_file = 'cleaned_{}.pkl'.format('processed_resume')\n",
    "        \n",
    "        utils = Utils()\n",
    "    \n",
    "        data_shuffled = utils.shuffle_data(self.resume_data)\n",
    "        data_processed_with_id = utils.clean_data(data_shuffled, cache_directory, cache_file=cache_file)\n",
    "        \n",
    "        shutil.rmtree('cache')\n",
    "        \n",
    "        utils.add_data_to_pickle('processed_resume', data_processed_with_id, self.save_to_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read cleaned data from cache file: cleaned_processed_resume.pkl\n"
     ]
    }
   ],
   "source": [
    "resume = RecruitmentPreprocess(path, save_to_path)\n",
    "# resume.save_resume_data_to_csv()\n",
    "# resume.add_resume_keys_to_pickle()\n",
    "# resume.add_user_accessible_resume_to_pickle()\n",
    "resume.add_processed_resume_to_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['resume_id_index', 'user_accessible_resume', 'processed_resume'])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_id_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_to_path+'data_dict.pkl', 'rb') as f:\n",
    "    cv_id_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Shashank']\n",
      "2                                                                                                                                                                                         Shashank Tiwari\n",
      "\n",
      "\n",
      "\n",
      "\t\t\n",
      "\n",
      "\t\tSHASHANK TIWARI\n",
      "\n",
      "Shashank.tiwari44@gmail.com                                                                                            (650) 600-1785 Jersey City, NJ (07306)\n",
      "\n",
      "\n",
      "\n",
      "SUMMARY:\n",
      "\n",
      "\t\tOver seven years of experience as Business Analyst/Scrum Master with solid understanding of Business Requirement gathering, Business Process Modeling and database/data warehouse experience\n",
      "\n",
      "\t\tExtensive experience of communicating with Subject Matter Experts (SME’s), performing requirement gathering, business analysis, data analysis, and documentation\n",
      "\n",
      "\t\tExpert in facilitating Agile ceremonies, coached team in JIRA, Service Now including concentrated efforts with product owner on user story/epic/feature optimization\n",
      "\n",
      "\t\tProficient in Agile engineering process such as Test Driven Development (TDD), Behavior driven Development (BDD), Continuous integration.\n",
      "\n",
      "Orchestrated various business analysis activities such as GAP, ROI, Risk, SWOT, Cost and Impact analysis.\n",
      "\n",
      "Excellent Business writing skills in writing business requirements document, USE Case specifications, functional specifications, systems design specifications, system requirements specifications, data dictionary, business continuity plan, and data/work flows\n",
      "\n",
      "4 Years of experience in Data Analysis, report generation, maintenance of business report processes, and data verifications and validations\n",
      "\n",
      "Proficient in defect management activities using JIRA, HP QC and Rational Clear Quest\n",
      "\n",
      "Experienced in tracking and managing requirements using Requirement Traceability Matrix (RTM)\n",
      "\n",
      "Specialist in creating Use Case Models, Process Flows Diagrams, Workflow Analysis and Functional Decomposition Analysis\n",
      "\n",
      "Proficient in writing queries, store procedures, triggers, views in SQL server and Oracle server\n",
      "\n",
      "Experience in Business Intelligence, Data analysis, Data mapping, Data Warehouse, CRM and ERP\n",
      "\n",
      "\t\tMasters - Business Administration; Post Graduate Diploma in Management.\n",
      "\n",
      "\t\t\n",
      "\n",
      "Application platforms & Environments:\n",
      "\n",
      "Databases             \n",
      "\n",
      "Oracle, MS Access, MS SQL, Teradata, Toad\n",
      "\n",
      "Tools\n",
      "\n",
      "Blue Prism, JIRA, SharePoint, Sales-Force, Version one, MS Visio, MS Project, HPALM\n",
      "\n",
      "Business Analysis\n",
      "\n",
      "SAP Crystal Reports, Tableau, CA Clarity, Balsamiq, Signavio\n",
      "\n",
      "Methodologies\n",
      "\n",
      " JAD, RUP, Waterfall, Agile-Scrum, SAFe, Kanban, Six Sigma, and ITIL.\n",
      "\n",
      "\n",
      "\n",
      "PROFESSIONAL EXPERIENCE:\n",
      "\n",
      "Goldman Sachs, New York (Client) \n",
      "\n",
      "Business Analyst:                                                                                                                                                         Sept 2017 – Present\n",
      "\n",
      "\n",
      "\n",
      "Facilitating and managing meeting sessions with committee of SMEs from various business areas including loan Servicing, Loan Monitoring and Asset Management\n",
      "\n",
      "Conducting user meetings to identify business rules and requirements and then documented them in a format that can be reviewed and understood by both business people and technical people.\n",
      "\n",
      "Created, managed and prioritized the Product Backlog.\n",
      "\n",
      "Conducted Product Backlog grooming sessions with product owner and facilitated Daily Scrum meetings.\n",
      "\n",
      "Elaborated the user stories with the development and QA and responsible for ensuring user stories have meet the acceptance criteria.\n",
      "\n",
      "Identify, manage and mitigate risks, impediments, and dependencies.\n",
      "\n",
      "Agile methodology mentor for new team members.\n",
      "\n",
      "Actively assisted in the acceptance and validation of the stories by testing the delivered stories.\n",
      "\n",
      "Performed disaster recovery tests to ensure system availability and functionality\n",
      "\n",
      "Responsible for analyzing report requirements and developing the reports and using MS SharePoint for centralized project documentation.\n",
      "\n",
      "Devised system to generate automated Business Intelligence reports for the internal users.\n",
      "\n",
      "Provide the data warehouse team with information to support the analysis of the data requirements for reporting.\n",
      "\n",
      "Prepared Business Process Models including business process flows from conceptual to procedural level, often applying BPR to optimize resource optimization\n",
      "\n",
      "Controlling project resources, planning and implementation using MS Project, SharePoint and AGILE methodologies\n",
      "\n",
      "Performing requirement elicitation from walkthroughs with the users and business developers. \n",
      "\n",
      "Assisting the technical team in translating application functionality into application architecture and the production of a System Functionality document\n",
      "\n",
      "Coordinated and performed Unit testing, Integration testing and Regression testing of the system with the QA team\n",
      "\n",
      "\n",
      "\n",
      "Texas Southern University, Houston\n",
      "\n",
      "Graduate Assistant:                                                                                                                                                      Jan 2016 - Jun 2017\n",
      "\n",
      "\n",
      "\n",
      "Worked extensively with the users and with different levels of management to identify requirements, Use cases and developed functional specifications\n",
      "\n",
      "Prepared Current  and future business process flow diagrams, integrated process flow diagrams to show one end-to-end business model and process mapping including swim lanes\n",
      "\n",
      "Conducted JAD sessions with management, SMEs’, Vendors, Users and other Stakeholders for open and pending issues\n",
      "\n",
      "Provided executive communications during all phases of the high severity incidents\n",
      "\n",
      "Used SharePoint for developing and maintaining an online resource site, including an \"encyclopedia\" that incorporates policies, procedures, best practices, FAQs, etc.\n",
      "\n",
      "Involved in all status meetings with users (QVC), as well as with different vendor teams\n",
      "\n",
      "Facilitated UAT, developing and maintaining quality procedures, and ensured that appropriate documentation is in place\n",
      "\n",
      "\n",
      "\n",
      "Dorset Kaba Security System Pvt Ltd, Delhi, India\n",
      "\n",
      "Sr. Business Analyst                                                                                                                                                      Sept 2014- Jul 2015\n",
      "\n",
      "\n",
      "\n",
      "Created a RACI matrix to enhance the project management and business analysis efforts, and streamline the recognition of roles and responsibilities of the entire project team, including the stakeholders, and sponsors, etc.\n",
      "\n",
      "Drafted Statement of work (SOW), user stories, and improved team performance with the help of team velocity, burndown charts.\n",
      "\n",
      "Facilitated Agile manifesto and servant leadership across the enterprise with version one \n",
      "\n",
      "Participated in Scrum Sessions, presented statistics about time estimation accuracy, team velocity, and burn down rate to manage each sprint.\n",
      "\n",
      "Led teams for building projects using software blue prism to automate IT/Business Process end to end\n",
      "\n",
      "Responsible for drafting business requirements, functional specifications, documentation and test plans\n",
      "\n",
      "Worked with project team to identify and map detailed current processes, identified gaps and failure points, performed root cause analysis and developed functional requirements that supported overall strategy, goals and objectives\n",
      "\n",
      "Created a continuous improvement process for my three departments leveraging KPI’s, and performance metrics resulting in all 3 departments going from not meeting their SLA’s to achieving the SLA’s.\n",
      "\n",
      "Managed a variety of contracts and subcontracts in accordance with company policies and procedures\n",
      "\n",
      "Assured compliance to required corporate standards, procedures, guidelines and processes, including audits.\n",
      "\n",
      "Assisted in development of training materials for new technology and process improvement\n",
      "\n",
      "Responsible for identifying and documenting business rules, prepared detailed Use Cases and conducted User Acceptance Testing\n",
      "\n",
      "Assisted QA team to developed test plan, test conditions and test cases to be used in testing based on business requirements and technical specifications\n",
      "\n",
      "\n",
      "\n",
      "Century Ply-boards (I) Ltd, Delhi, India\n",
      "\n",
      "Sr. Business Analyst:                                                                                                                                                        Apr 2012 - Aug 2014\n",
      "\n",
      "\n",
      "\n",
      "Extracted and Gathered the business requirements like extensive search capabilities, sourcing tools from the business experts and architects, developed Functional Specifications and User cases\n",
      "\n",
      "Worked Tremendously on SALESFORCE CRM to set up new accounts, manage teams and issue resolution\n",
      "\n",
      "Involved in writing Business Rules to support recommendations for resolving business and technical issues\n",
      "\n",
      "Participated in SWAT meetings (JAD Sessions) to develop an architectural solution and ensure that the application meets the business requirements, resolve open issues, and change requests \n",
      "\n",
      "Analyzed Software Requirements documents and Business Requirements documents to get a better understanding of the system on both Technical and Business perspectives\n",
      "\n",
      "Created Use Case Diagrams, and Activity Diagrams, using MS Visio according to UML methodology\n",
      "\n",
      "Conducted GAP Analysis in understanding how the upgraded system carries out the business functions and assists in ensuring the timely and effective implementation\n",
      "\n",
      "Conducted and participated in walkthroughs to discuss issues with the development, design and QA team\n",
      "\n",
      "Interacted with the Developers, QA and Engineering teams for resolving the report bugs and technical issues through Sales force CRM by SQL querying on “TOAD”\n",
      "\n",
      "Extensively worked with QA team to perform Unit testing and regression testing.\n",
      "\n",
      "Conducted User-Acceptance Testing before the release of the product to Business. \n",
      "\n",
      "\n",
      "\n",
      "ANG India Ltd, Delhi, India\n",
      "\n",
      "Business Analyst:                                                                                                                                                         Nov 2010 - Mar 2012\n",
      "\n",
      "Interacted with Users and Stakeholders to identify business system needs, evaluated solutions for business problems\n",
      "\n",
      "Analyzed and documented information system requirements and the corresponding impact on business processes\n",
      "\n",
      "Conducted JAD sessions to allow different stakeholders to communicate with each other, resolve problems at early stage\n",
      "\n",
      "Studied the Business Requirement Document (BRD), supporting documents containing essential business elements, detailed definition and description of the relationship between the actors\n",
      "\n",
      "Designed and developed Use Case Diagrams, Activity Diagrams, and Data Flow Diagrams to define the Business Process\n",
      "\n",
      "Analyzed the data entity relationships and worked on multiple short term projects in between.\n",
      "\n",
      "Worked as a team with other business analysts to make an object oriented model of the application and created use cases \n",
      "\n",
      "Hands on experience in working with active directory, to give privileges and access to the users according to their roles and designations\n",
      "\n",
      "Coordinated with users  for  User acceptance testing (UAT) and  QA team for system testing such as unit testing, integration testing and regression testing\n",
      "\n",
      "\n",
      "\n",
      "India Bulls, Gurgaon, India \n",
      "\n",
      "Analyst:                                                                                                                                                                        Jul 2008- May 2009\n",
      "\n",
      "\n",
      "\n",
      "Responsible for drafting and reviewing business requirements, functional specifications, project schedules,     documentation and test plans\n",
      "\n",
      "Designed the business requirement collection approach based on the project scope and SDLC Methodology Conducted interviews with key business users to collect requirement and business process information\n",
      "\n",
      "Worked with SME’s of different groups to gain detailed knowledge of Investments and Capital Market and also to understand the cross impacts of the system\n",
      "\n",
      "Developed business process models in RUP to document existing and future business processes\n",
      "\n",
      "Performed extensive requirement analysis including data analysis and gap analysis\n",
      "\n",
      "Functioned as the primary liaison between the business line, operations, and the technical areas throughout the project cycle\n",
      "\n",
      "Extensively worked on MS Access, MS Excel, MS Word, PowerPoint, SQL, MS Project\n",
      "\n",
      "Partnered with the technical areas in the research and resolution of system and process problems\n",
      "\n",
      "Conducted benchmarking activities to identify best practices\n",
      "\n",
      "\n",
      "\n",
      "EDUCATION:\n",
      "\n",
      "Masters -Business Administration (MBA)                                                                                            Aug 2015- May 2017                                                                       \n",
      "\n",
      "Jessie H. Jones School of Business, Texas Southern University, Houston Texas.\n",
      "\n",
      "Post Graduate of Diploma in Management                                                                                                                     2011\n",
      "\n",
      "Institute of Productivity & Management Ghaziabad, U.P India \n",
      "\n",
      "Bachelor in Science                                                                                                                                                               2008                                                                                                          \n",
      "\n",
      "S.S Degree College Kanpur, India.\n",
      "\n",
      "Certification:\n",
      "\n",
      "Scrum Master Accredited Certification                                                                                                                     Sep 2017                                                                    \n",
      "\n",
      "International Scrum Institute\n"
     ]
    }
   ],
   "source": [
    "print(cv_id_index['resume_id_index'][174])\n",
    "print(cv_id_index['user_accessible_resume'][174])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[174, ['2', 'shashank', 'tiwari', 'shashank', 'tiwari', 'shashank', 'tiwari44', 'gmail', 'com', '650', '600', '1785', 'jersey', 'citi', 'nj', '07306', 'summari', 'seven', 'year', 'experi', 'busi', 'analyst', 'scrum', 'master', 'solid', 'understand', 'busi', 'requir', 'gather', 'busi', 'process', 'model', 'databas', 'data', 'warehous', 'experi', 'extens', 'experi', 'commun', 'subject', 'matter', 'expert', 'sme', 'perform', 'requir', 'gather', 'busi', 'analysi', 'data', 'analysi', 'document', 'expert', 'facilit', 'agil', 'ceremoni', 'coach', 'team', 'jira', 'servic', 'includ', 'concentr', 'effort', 'product', 'owner', 'user', 'stori', 'epic', 'featur', 'optim', 'profici', 'agil', 'engin', 'process', 'test', 'driven', 'develop', 'tdd', 'behavior', 'driven', 'develop', 'bdd', 'continu', 'integr', 'orchestr', 'variou', 'busi', 'analysi', 'activ', 'gap', 'roi', 'risk', 'swot', 'cost', 'impact', 'analysi', 'excel', 'busi', 'write', 'skill', 'write', 'busi', 'requir', 'document', 'use', 'case', 'specif', 'function', 'specif', 'system', 'design', 'specif', 'system', 'requir', 'specif', 'data', 'dictionari', 'busi', 'continu', 'plan', 'data', 'work', 'flow', '4', 'year', 'experi', 'data', 'analysi', 'report', 'gener', 'mainten', 'busi', 'report', 'process', 'data', 'verif', 'valid', 'profici', 'defect', 'manag', 'activ', 'use', 'jira', 'hp', 'qc', 'ration', 'clear', 'quest', 'experienc', 'track', 'manag', 'requir', 'use', 'requir', 'traceabl', 'matrix', 'rtm', 'specialist', 'creat', 'use', 'case', 'model', 'process', 'flow', 'diagram', 'workflow', 'analysi', 'function', 'decomposit', 'analysi', 'profici', 'write', 'queri', 'store', 'procedur', 'trigger', 'view', 'sql', 'server', 'oracl', 'server', 'experi', 'busi', 'intellig', 'data', 'analysi', 'data', 'map', 'data', 'warehous', 'crm', 'erp', 'master', 'busi', 'administr', 'post', 'graduat', 'diploma', 'manag', 'applic', 'platform', 'environ', 'databas', 'oracl', 'ms', 'access', 'ms', 'sql', 'teradata', 'toad', 'tool', 'blue', 'prism', 'jira', 'sharepoint', 'sale', 'forc', 'version', 'one', 'ms', 'visio', 'ms', 'project', 'hpalm', 'busi', 'analysi', 'sap', 'crystal', 'report', 'tableau', 'ca', 'clariti', 'balsamiq', 'signavio', 'methodolog', 'jad', 'rup', 'waterfal', 'agil', 'scrum', 'safe', 'kanban', 'six', 'sigma', 'itil', 'profession', 'experi', 'goldman', 'sach', 'new', 'york', 'client', 'busi', 'analyst', 'sept', '2017', 'present', 'facilit', 'manag', 'meet', 'session', 'committe', 'sme', 'variou', 'busi', 'area', 'includ', 'loan', 'servic', 'loan', 'monitor', 'asset', 'manag', 'conduct', 'user', 'meet', 'identifi', 'busi', 'rule', 'requir', 'document', 'format', 'review', 'understood', 'busi', 'peopl', 'technic', 'peopl', 'creat', 'manag', 'priorit', 'product', 'backlog', 'conduct', 'product', 'backlog', 'groom', 'session', 'product', 'owner', 'facilit', 'daili', 'scrum', 'meet', 'elabor', 'user', 'stori', 'develop', 'qa', 'respons', 'ensur', 'user', 'stori', 'meet', 'accept', 'criteria', 'identifi', 'manag', 'mitig', 'risk', 'impedi', 'depend', 'agil', 'methodolog', 'mentor', 'new', 'team', 'member', 'activ', 'assist', 'accept', 'valid', 'stori', 'test', 'deliv', 'stori', 'perform', 'disast', 'recoveri', 'test', 'ensur', 'system', 'avail', 'function', 'respons', 'analyz', 'report', 'requir', 'develop', 'report', 'use', 'ms', 'sharepoint', 'central', 'project', 'document', 'devis', 'system', 'gener', 'autom', 'busi', 'intellig', 'report', 'intern', 'user', 'provid', 'data', 'warehous', 'team', 'inform', 'support', 'analysi', 'data', 'requir', 'report', 'prepar', 'busi', 'process', 'model', 'includ', 'busi', 'process', 'flow', 'conceptu', 'procedur', 'level', 'often', 'appli', 'bpr', 'optim', 'resourc', 'optim', 'control', 'project', 'resourc', 'plan', 'implement', 'use', 'ms', 'project', 'sharepoint', 'agil', 'methodolog', 'perform', 'requir', 'elicit', 'walkthrough', 'user', 'busi', 'develop', 'assist', 'technic', 'team', 'translat', 'applic', 'function', 'applic', 'architectur', 'product', 'system', 'function', 'document', 'coordin', 'perform', 'unit', 'test', 'integr', 'test', 'regress', 'test', 'system', 'qa', 'team', 'texa', 'southern', 'univers', 'houston', 'graduat', 'assist', 'jan', '2016', 'jun', '2017', 'work', 'extens', 'user', 'differ', 'level', 'manag', 'identifi', 'requir', 'use', 'case', 'develop', 'function', 'specif', 'prepar', 'current', 'futur', 'busi', 'process', 'flow', 'diagram', 'integr', 'process', 'flow', 'diagram', 'show', 'one', 'end', 'end', 'busi', 'model', 'process', 'map', 'includ', 'swim', 'lane', 'conduct', 'jad', 'session', 'manag', 'sme', 'vendor', 'user', 'stakehold', 'open', 'pend', 'issu', 'provid', 'execut', 'commun', 'phase', 'high', 'sever', 'incid', 'use', 'sharepoint', 'develop', 'maintain', 'onlin', 'resourc', 'site', 'includ', 'encyclopedia', 'incorpor', 'polici', 'procedur', 'best', 'practic', 'faq', 'etc', 'involv', 'statu', 'meet', 'user', 'qvc', 'well', 'differ', 'vendor', 'team', 'facilit', 'uat', 'develop', 'maintain', 'qualiti', 'procedur', 'ensur', 'appropri', 'document', 'place', 'dorset', 'kaba', 'secur', 'system', 'pvt', 'ltd', 'delhi', 'india', 'sr', 'busi', 'analyst', 'sept', '2014', 'jul', '2015', 'creat', 'raci', 'matrix', 'enhanc', 'project', 'manag', 'busi', 'analysi', 'effort', 'streamlin', 'recognit', 'role', 'respons', 'entir', 'project', 'team', 'includ', 'stakehold', 'sponsor', 'etc', 'draft', 'statement', 'work', 'sow', 'user', 'stori', 'improv', 'team', 'perform', 'help', 'team', 'veloc', 'burndown', 'chart', 'facilit', 'agil', 'manifesto', 'servant', 'leadership', 'across', 'enterpris', 'version', 'one', 'particip', 'scrum', 'session', 'present', 'statist', 'time', 'estim', 'accuraci', 'team', 'veloc', 'burn', 'rate', 'manag', 'sprint', 'led', 'team', 'build', 'project', 'use', 'softwar', 'blue', 'prism', 'autom', 'busi', 'process', 'end', 'end', 'respons', 'draft', 'busi', 'requir', 'function', 'specif', 'document', 'test', 'plan', 'work', 'project', 'team', 'identifi', 'map', 'detail', 'current', 'process', 'identifi', 'gap', 'failur', 'point', 'perform', 'root', 'caus', 'analysi', 'develop', 'function', 'requir', 'support', 'overal', 'strategi', 'goal', 'object', 'creat', 'continu', 'improv', 'process', 'three', 'depart', 'leverag', 'kpi', 'perform', 'metric', 'result', '3', 'depart', 'go', 'meet', 'sla', 'achiev', 'sla', 'manag', 'varieti', 'contract', 'subcontract', 'accord', 'compani', 'polici', 'procedur', 'assur', 'complianc', 'requir', 'corpor', 'standard', 'procedur', 'guidelin', 'process', 'includ', 'audit', 'assist', 'develop', 'train', 'materi', 'new', 'technolog', 'process', 'improv', 'respons', 'identifi', 'document', 'busi', 'rule', 'prepar', 'detail', 'use', 'case', 'conduct', 'user', 'accept', 'test', 'assist', 'qa', 'team', 'develop', 'test', 'plan', 'test', 'condit', 'test', 'case', 'use', 'test', 'base', 'busi', 'requir', 'technic', 'specif', 'centuri', 'pli', 'board', 'ltd', 'delhi', 'india', 'sr', 'busi', 'analyst', 'apr', '2012', 'aug', '2014', 'extract', 'gather', 'busi', 'requir', 'like', 'extens', 'search', 'capabl', 'sourc', 'tool', 'busi', 'expert', 'architect', 'develop', 'function', 'specif', 'user', 'case', 'work', 'tremend', 'salesforc', 'crm', 'set', 'new', 'account', 'manag', 'team', 'issu', 'resolut', 'involv', 'write', 'busi', 'rule', 'support', 'recommend', 'resolv', 'busi', 'technic', 'issu', 'particip', 'swat', 'meet', 'jad', 'session', 'develop', 'architectur', 'solut', 'ensur', 'applic', 'meet', 'busi', 'requir', 'resolv', 'open', 'issu', 'chang', 'request', 'analyz', 'softwar', 'requir', 'document', 'busi', 'requir', 'document', 'get', 'better', 'understand', 'system', 'technic', 'busi', 'perspect', 'creat', 'use', 'case', 'diagram', 'activ', 'diagram', 'use', 'ms', 'visio', 'accord', 'uml', 'methodolog', 'conduct', 'gap', 'analysi', 'understand', 'upgrad', 'system', 'carri', 'busi', 'function', 'assist', 'ensur', 'time', 'effect', 'implement', 'conduct', 'particip', 'walkthrough', 'discuss', 'issu', 'develop', 'design', 'qa', 'team', 'interact', 'develop', 'qa', 'engin', 'team', 'resolv', 'report', 'bug', 'technic', 'issu', 'sale', 'forc', 'crm', 'sql', 'queri', 'toad', 'extens', 'work', 'qa', 'team', 'perform', 'unit', 'test', 'regress', 'test', 'conduct', 'user', 'accept', 'test', 'releas', 'product', 'busi', 'ang', 'india', 'ltd', 'delhi', 'india', 'busi', 'analyst', 'nov', '2010', 'mar', '2012', 'interact', 'user', 'stakehold', 'identifi', 'busi', 'system', 'need', 'evalu', 'solut', 'busi', 'problem', 'analyz', 'document', 'inform', 'system', 'requir', 'correspond', 'impact', 'busi', 'process', 'conduct', 'jad', 'session', 'allow', 'differ', 'stakehold', 'commun', 'resolv', 'problem', 'earli', 'stage', 'studi', 'busi', 'requir', 'document', 'brd', 'support', 'document', 'contain', 'essenti', 'busi', 'element', 'detail', 'definit', 'descript', 'relationship', 'actor', 'design', 'develop', 'use', 'case', 'diagram', 'activ', 'diagram', 'data', 'flow', 'diagram', 'defin', 'busi', 'process', 'analyz', 'data', 'entiti', 'relationship', 'work', 'multipl', 'short', 'term', 'project', 'work', 'team', 'busi', 'analyst', 'make', 'object', 'orient', 'model', 'applic', 'creat', 'use', 'case', 'hand', 'experi', 'work', 'activ', 'directori', 'give', 'privileg', 'access', 'user', 'accord', 'role', 'design', 'coordin', 'user', 'user', 'accept', 'test', 'uat', 'qa', 'team', 'system', 'test', 'unit', 'test', 'integr', 'test', 'regress', 'test', 'india', 'bull', 'gurgaon', 'india', 'analyst', 'jul', '2008', 'may', '2009', 'respons', 'draft', 'review', 'busi', 'requir', 'function', 'specif', 'project', 'schedul', 'document', 'test', 'plan', 'design', 'busi', 'requir', 'collect', 'approach', 'base', 'project', 'scope', 'sdlc', 'methodolog', 'conduct', 'interview', 'key', 'busi', 'user', 'collect', 'requir', 'busi', 'process', 'inform', 'work', 'sme', 'differ', 'group', 'gain', 'detail', 'knowledg', 'invest', 'capit', 'market', 'also', 'understand', 'cross', 'impact', 'system', 'develop', 'busi', 'process', 'model', 'rup', 'document', 'exist', 'futur', 'busi', 'process', 'perform', 'extens', 'requir', 'analysi', 'includ', 'data', 'analysi', 'gap', 'analysi', 'function', 'primari', 'liaison', 'busi', 'line', 'oper', 'technic', 'area', 'throughout', 'project', 'cycl', 'extens', 'work', 'ms', 'access', 'ms', 'excel', 'ms', 'word', 'powerpoint', 'sql', 'ms', 'project', 'partner', 'technic', 'area', 'research', 'resolut', 'system', 'process', 'problem', 'conduct', 'benchmark', 'activ', 'identifi', 'best', 'practic', 'educ', 'master', 'busi', 'administr', 'mba', 'aug', '2015', 'may', '2017', 'jessi', 'h', 'jone', 'school', 'busi', 'texa', 'southern', 'univers', 'houston', 'texa', 'post', 'graduat', 'diploma', 'manag', '2011', 'institut', 'product', 'manag', 'ghaziabad', 'u', 'p', 'india', 'bachelor', 'scienc', '2008', 'degre', 'colleg', 'kanpur', 'india', 'certif', 'scrum', 'master', 'accredit', 'certif', 'sep', '2017', 'intern', 'scrum', 'institut']]\n"
     ]
    }
   ],
   "source": [
    "print(cv_id_index['processed_resume'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-3559593e16e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "[4][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
